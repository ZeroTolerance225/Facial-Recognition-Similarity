{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c18f75-3d60-48b6-8872-831422719015",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (0.16.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests->torchvision) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8372c097-b408-450e-b02f-7dc9c4e9118b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877c26be-9ee4-4b91-8a80-006c4da8c7b0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (8.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (10.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryanb\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4072368-9c1a-404f-bc5f-fedcf9b79091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ExifTags\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec5e18-2c37-4181-b38c-484adc21635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 8400])\n",
      "[321.9969787597656, 251.54086303710938, 135.28253173828125, 143.34117126464844, 0.9363659024238586]\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_path, model_class=None):\n",
    "    # loading a custom model\n",
    "    model = torch.load(model_path)\n",
    "    model =  model['model'].float()\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "def prepare_image(image_path, input_size, training_mode=False):\n",
    "    # Load image with PIL\n",
    "    with Image.open(image_path) as img:\n",
    "        # Auto-Orient: applying orientation from image EXIF data\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                break\n",
    "        exif = img._getexif()\n",
    "\n",
    "        if exif is not None:\n",
    "            orientation = exif.get(orientation, 1)\n",
    "            rotations = {\n",
    "                3: Image.ROTATE_180,\n",
    "                6: Image.ROTATE_270,\n",
    "                8: Image.ROTATE_90\n",
    "            }\n",
    "            if orientation in rotations:\n",
    "                img = img.transpose(rotations[orientation])\n",
    "\n",
    "        # Resize the image\n",
    "        img = img.resize(input_size, Image.BOX)\n",
    "\n",
    "        # Convert image to RGB (in case it's not already in that format)\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "        # Define transformations\n",
    "        transform_list = [transforms.ToTensor()]\n",
    "\n",
    "        # Apply horizontal flip randomly if in training mode\n",
    "        if training_mode:\n",
    "            transform_list.append(transforms.RandomHorizontalFlip(p=1.0))  # Always apply horizontal flip during training\n",
    "\n",
    "        # Combine all transformations\n",
    "        transform = transforms.Compose(transform_list)\n",
    "        \n",
    "        # Apply transformations\n",
    "        image = transform(img)\n",
    "\n",
    "        # Add batch dimension\n",
    "        image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def run_inference(model, image):\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        output = model(image)\n",
    "    #print(\"Output type:\", type(output))  # Check the type of output\n",
    "    #if isinstance(output, tuple):\n",
    "        #for i, tensor in enumerate(output):\n",
    "            #print(f\"Tensor {i} shape:\", tensor.shape)\n",
    "    return output\n",
    "\n",
    "\n",
    "def process_output(output):\n",
    "    # Assuming output is the first tensor in the tuple and has a shape of [1, 6, 8400]\n",
    "    output = output[0]\n",
    "    highest_confidence = 0\n",
    "    hc_index = 0\n",
    "    result = []\n",
    "    print(output.shape)\n",
    "    # Reshape from [1, 6, 8400] to [8400, 6] to simplify\n",
    "    #predictions = output  # Flatten the batch and attributes dimensions\n",
    "    for i in range(0,8400,1):\n",
    "        if(output[0][4][i] > highest_confidence):\n",
    "            highest_confidence = output[0][4][i]\n",
    "            hc_index = i\n",
    "\n",
    "    for i in range(0, 5, 1):\n",
    "        result.append(output[0][i][hc_index].item())\n",
    "\n",
    "    # Filter out predictions with a low confidence score\n",
    "    # Assuming the confidence score is at index 4\n",
    "    #confidence_threshold = 0.5\n",
    "    #mask = predictions[:, 4] > confidence_threshold\n",
    "    #filtered_predictions = predictions[mask]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def draw_boxes(image, box):\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize the image to the model's input size (640x640)\n",
    "    resized_image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    # Unpack center coordinates, width, height, and confidence from the bounding box\n",
    "    cx, cy, w, h, conf = box\n",
    "\n",
    "    # Convert from [center x, center y, width, height] to [x1, y1, x2, y2]\n",
    "    x1 = int(cx - w / 2)\n",
    "    y1 = int(cy - h / 2)\n",
    "    x2 = int(cx + w / 2)\n",
    "    y2 = int(cy + h / 2)\n",
    "\n",
    "    # Draw the rectangle on the resized image\n",
    "    color = (0, 255, 0)  # Green color in BGR\n",
    "    cv2.rectangle(resized_image, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "    # Put the confidence score on the image\n",
    "    cv2.putText(resized_image, f'Conf: {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "def crop_to_box(image, box):\n",
    "    # Load the original image\n",
    "    \n",
    "\n",
    "    # Resize the image to the model's input size (640x640)\n",
    "    resized_image = cv2.resize(image, (640, 640))\n",
    "\n",
    "    # Unpack center coordinates, width, height from the bounding box\n",
    "    cx, cy, w, h = box[:4]\n",
    "\n",
    "    # Convert from [center x, center y, width, height] to [x1, y1, x2, y2]\n",
    "    x1 = int((cx - w / 2))\n",
    "    y1 = int((cy - h / 2))\n",
    "    x2 = int((cx + w / 2))\n",
    "    y2 = int((cy + h / 2))\n",
    "\n",
    "    # Crop the image to the bounding box\n",
    "    # Make sure coordinates do not go out of image bounds\n",
    "    x1 = max(x1, 0)\n",
    "    y1 = max(y1, 0)\n",
    "    x2 = min(x2, 640)\n",
    "    y2 = min(y2, 640)\n",
    "\n",
    "    cropped_image = resized_image[y1:y2, x1:x2]\n",
    "    #cropped_image = cv2.resize(cropped_image,(224,224))\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def resize_image(image, scale_percent):\n",
    "    \"\"\"\n",
    "    Resize the image by a certain percentage.\n",
    "    :param image: Original image.\n",
    "    :param scale_percent: Percentage to scale (50 means 50%, etc.).\n",
    "    :return: Resized image.\n",
    "    \"\"\"\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "    model_path = 'best_3.pt'  # Path to your model file\n",
    "    image_path = './images/alan.jpg'  # Path to your test image\n",
    "    \n",
    "    # Load the model, adjust the class as necessary\n",
    "    model = load_model(model_path, model_class=None)  # Use `model_class=YourModelClass` if needed\n",
    "    \n",
    "    # Prepare the image\n",
    "    prepared_image = prepare_image(image_path, input_size=(640, 640))  # Adjust size as per your model's requirement\n",
    "    \n",
    "    # Run inference\n",
    "    output = run_inference(model, prepared_image)\n",
    "    \n",
    "    # Interpret output\n",
    "    top_prediction = process_output(output)\n",
    "    print(top_prediction)\n",
    "\n",
    "    original_image = cv2.imread(image_path)\n",
    "    result_image = crop_to_box(original_image, top_prediction)\n",
    "    #result_image = resize_image(result_image, scale_percent=100)\n",
    "    cv2.imshow('Detected Object with Highest Confidence', result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b34d6-98f0-455c-9008-b69864fbbe28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
